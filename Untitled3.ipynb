{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HzurODmpVgz-"
      },
      "outputs": [],
      "source": [
        "pip install beautifulsoup4"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import time\n",
        "\n",
        "# Base URL\n",
        "base_url = \"https://www.shl.com/solutions/products/product-catalog/\"\n",
        "\n",
        "scrap_data=[]\n",
        "\n",
        "# Function to extract data from a single table wrapper\n",
        "def extract_assessments_from_table(table_div):\n",
        "    table = table_div.find('table')\n",
        "    if not table:\n",
        "        return\n",
        "\n",
        "    for row in table.find_all('tr')[1:]:  # Skip header\n",
        "        cols = row.find_all('td')\n",
        "\n",
        "        if len(cols) >= 4:\n",
        "            job_solution_link = cols[0].find('a')\n",
        "            job_solution_text = job_solution_link.text.strip() if job_solution_link else \"\"\n",
        "            job_solution_url = job_solution_link['href'] if job_solution_link else \"\"\n",
        "\n",
        "            remote_testing = \"Yes\" if cols[1].find('span', class_='catalogue__circle -yes') else \"No\"\n",
        "            adaptive_irt = \"Yes\" if cols[2].text.strip() == '✓' else \"No\"\n",
        "\n",
        "            test_types = [span.text.strip() for span in cols[3].find_all('span', class_='product-catalogue__key')]\n",
        "\n",
        "            scrap_data.append({\n",
        "                \"Job Solution\": job_solution_text,\n",
        "                \"Link\": job_solution_url,\n",
        "                \"Remote Testing\": remote_testing,\n",
        "                \"Adaptive/IRT\": adaptive_irt,\n",
        "                \"Test Types\": \", \".join(test_types)\n",
        "            })\n",
        "\n",
        "# Loop through pages from start=12 to 132 (12 * 0 to 12 * 11)\n",
        "for i in range(0, 12):\n",
        "    start_value = 12 * i\n",
        "    url = f\"{base_url}?start={start_value}&type=2&type=2\"\n",
        "\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "    table_wrappers = soup.find_all('div', class_='custom__table-wrapper')\n",
        "    for table_div in table_wrappers:\n",
        "        extract_assessments_from_table(table_div)\n",
        "\n",
        "    time.sleep(1)  # Optional: pause between requests\n",
        "\n",
        "# Print results\n",
        "for item in scrap_data:\n",
        "    print(item)\n"
      ],
      "metadata": {
        "id": "USoJNh9bVnUO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_assessment_duration(detail_url, retries=3, delay=2):\n",
        "    for attempt in range(retries):\n",
        "        try:\n",
        "            headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
        "            response = requests.get(detail_url, headers=headers, timeout=10)\n",
        "\n",
        "            if response.status_code == 404:\n",
        "                print(f\"404 Not Found: {detail_url}\")\n",
        "                return None\n",
        "\n",
        "            if response.status_code != 200:\n",
        "                print(f\"Status code {response.status_code} for {detail_url}\")\n",
        "                continue\n",
        "\n",
        "            soup = BeautifulSoup(response.content, 'html.parser')\n",
        "            for row in soup.find_all('div', class_='product-catalogue-training-calendar__row'):\n",
        "                p_tag = row.find('p')\n",
        "                if p_tag:\n",
        "                    match = re.search(r'Approximate Completion Time in minutes\\s*=\\s*(\\d+)', p_tag.text)\n",
        "                    if match:\n",
        "                        return int(match.group(1))\n",
        "            return None\n",
        "\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            print(f\"Error fetching {detail_url}: {e}\")\n",
        "            time.sleep(delay * (2 ** attempt))  # exponential backoff\n",
        "\n",
        "    return None\n"
      ],
      "metadata": {
        "id": "CaC5LR2JVt1j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import urllib.parse\n",
        "\n",
        "\n",
        "def format_job_solution_to_url(job_solution):\n",
        "    slug = job_solution.lower()\n",
        "    slug = slug.replace('+', '-')\n",
        "    slug = slug.replace(\".\", \"-\")\n",
        "    slug = slug.replace(\"’\", \"\")\n",
        "    slug = slug.replace(\"&\", \"and\")\n",
        "\n",
        "    # Keep parentheses for encoding\n",
        "    slug = re.sub(r'[^a-z0-9\\s()\\-]', '', slug)  # Keep (), hyphens, letters/numbers/spaces\n",
        "    slug = re.sub(r'\\s+', '-', slug)             # Replace spaces with hyphens\n",
        "    slug = re.sub(r'-+', '-', slug)              # Remove duplicate hyphens\n",
        "\n",
        "    slug = urllib.parse.quote(slug)              # Now encode the final string (turns () into %28 and %29)\n",
        "    return slug.strip('-') + '/'\n",
        "\n"
      ],
      "metadata": {
        "id": "w2FutCSfWHFr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_detail_url = \"https://www.shl.com/solutions/products/product-catalog/view/\"\n",
        "\n",
        "for item in scrap_data:\n",
        "    job_solution = item[\"Job Solution\"]\n",
        "    job_slug = format_job_solution_to_url(job_solution)\n",
        "    detail_url = base_detail_url + job_slug\n",
        "    print(f\"Fetching: {detail_url}\")\n",
        "\n",
        "    item['Duration'] = get_assessment_duration(detail_url)\n",
        "\n",
        "    # Respectful delay between requests\n",
        "    time.sleep(random.uniform(2, 4))\n"
      ],
      "metadata": {
        "id": "imp5c2xmV5iz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.DataFrame(scrap_data)"
      ],
      "metadata": {
        "id": "rQBFhxAcWdY0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count how many NaN values are in the 'Duration' column\n",
        "df['Duration'].isna().sum()\n"
      ],
      "metadata": {
        "id": "58VVlGPaWOxK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set duration for a row where Job Solution matches\n",
        "df.loc[df['Job Solution'] == 'Workplace Safety - Team 7.1 (International)', 'Duration'] = 20"
      ],
      "metadata": {
        "id": "HbOTa1EgWQuu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the DataFrame as a CSV file\n",
        "df.to_csv('shl_data.csv', index=False)"
      ],
      "metadata": {
        "id": "3RHc4GgcWS_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.fillna({'Duration (min)': None}, inplace=True)"
      ],
      "metadata": {
        "id": "otK0_RtSWZza"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_url = \"https://www.shl.com\"\n",
        "df['Link'] = df['Link'].apply(lambda x: f\"{base_url}{x}\" if x.startswith('/') else x)"
      ],
      "metadata": {
        "id": "gWT8MThdWb0z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop_duplicates(inplace=True)"
      ],
      "metadata": {
        "id": "pWO0mEo8WgYD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import gradio as gr\n",
        "\n",
        "# Load data\n",
        "df = pd.read_csv(\"shl_data1.csv\")\n",
        "\n",
        "# Check required columns\n",
        "required_columns = ['Job Solution', 'Link', 'Remote Testing', 'Adaptive/IRT', 'Duration', 'Test Types']\n",
        "for col in required_columns:\n",
        "    if col not in df.columns:\n",
        "        raise ValueError(f\"Missing required column: {col}\")\n",
        "\n",
        "# Load model and embed job solutions\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "df['Embedding'] = df['Job Solution'].apply(lambda x: model.encode(x))\n",
        "\n",
        "def recommend(query, num_recommendations=10):\n",
        "    query_emb = model.encode(query).reshape(1, -1)\n",
        "    similarities = cosine_similarity(query_emb, df['Embedding'].tolist())[0]\n",
        "\n",
        "    df_temp = df.copy()\n",
        "    df_temp['Similarity'] = similarities\n",
        "    top_results = df_temp.sort_values('Similarity', ascending=False).head(num_recommendations)\n",
        "\n",
        "    # Create HTML table\n",
        "    html = \"<table style='width:100%; border-collapse: collapse;'>\"\n",
        "    html += \"<tr><th style='border: 1px solid #ccc;'>Job Solution</th><th style='border: 1px solid #ccc;'>Link</th><th style='border: 1px solid #ccc;'>Remote Testing</th><th style='border: 1px solid #ccc;'>Adaptive/IRT</th><th style='border: 1px solid #ccc;'>Duration</th><th style='border: 1px solid #ccc;'>Test Types</th></tr>\"\n",
        "\n",
        "    for _, row in top_results.iterrows():\n",
        "        html += f\"\"\"\n",
        "        <tr>\n",
        "            <td style='border: 1px solid #ccc;'>{row['Job Solution']}</td>\n",
        "            <td style='border: 1px solid #ccc;'><a href=\"{row['Link']}\" target=\"_blank\">Click here</a></td>\n",
        "            <td style='border: 1px solid #ccc;'>{row['Remote Testing']}</td>\n",
        "            <td style='border: 1px solid #ccc;'>{row['Adaptive/IRT']}</td>\n",
        "            <td style='border: 1px solid #ccc;'>{row['Duration']}</td>\n",
        "            <td style='border: 1px solid #ccc;'>{row['Test Types']}</td>\n",
        "        </tr>\n",
        "        \"\"\"\n",
        "\n",
        "    html += \"</table>\"\n",
        "    return html\n",
        "\n",
        "# Gradio interface using HTML output\n",
        "iface = gr.Interface(\n",
        "    fn=recommend,\n",
        "    inputs=[\n",
        "        gr.Textbox(label=\"Query\", placeholder=\"e.g. 'Software developer with problem-solving skills'\"),\n",
        "        gr.Slider(1, 20, value=10, step=1, label=\"Number of Recommendations\")\n",
        "    ],\n",
        "    outputs=gr.HTML(label=\"Top SHL Assessment Recommendations\"),\n",
        "    examples=[\n",
        "        [\"Entry-level marketing role\", 5],\n",
        "        [\"Senior software engineer position\", 3],\n",
        "        [\"Customer service representative\", 10]\n",
        "    ],\n",
        "    title=\"SHL Assessment Recommender\",\n",
        "    description=\"Enter a job description to get relevant SHL assessment suggestions. Links are fully clickable!\"\n",
        ")\n",
        "\n",
        "iface.launch()\n"
      ],
      "metadata": {
        "id": "Dx6zFPvsWn_M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(\"shl_data1.csv\")\n",
        "\n",
        "# Check required columns\n",
        "required_columns = ['Job Solution', 'Link', 'Remote Testing', 'Adaptive/IRT', 'Duration', 'Test Types']\n",
        "for col in required_columns:\n",
        "    if col not in df.columns:\n",
        "        raise ValueError(f\"Missing required column: {col}\")\n",
        "\n",
        "# Load pre-trained model and generate embeddings\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "df['Embedding'] = df['Job Solution'].apply(lambda x: model.encode(x).tolist())"
      ],
      "metadata": {
        "id": "GV_lc0yOsnS6"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(\"preprocess_data.csv\", index=False)"
      ],
      "metadata": {
        "id": "sSQRjHF8spuD"
      },
      "execution_count": 45,
      "outputs": []
    }
  ]
}